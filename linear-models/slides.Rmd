---
title: '(Bayesian) linear mixed-effects models'
author: '<span style="font-size: 40px; font-face: bold">Jens Roeser</span>'
output: 
  ioslides_presentation:
    incremental: false
    transition: slower
    widescreen: true
    css: slides.css
#    logo: ../gfx/ntu.png
bibliography      : ["../references.bib"]
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, eval = TRUE, message = FALSE, comment=NA)
options("kableExtra.html.bsTable" = T, digits = 3)
options(pillar.print_min = 5, pillar.print_max = 6)
library(tidyverse)
library(knitr)
library(kableExtra)
library(patchwork)
library(magick)
library(brms)
library(ggthemes)
library(mixtools)
library(tidygraph)
library(ggraph)
theme_set(theme_bw(base_size = 18) +
            theme(legend.position = "top", 
                  legend.justification = "right"))
```


## In case you weren't around on Monday

- Go to [github.com/jensroes/bristol-ws-2025](https://github.com/jensroes/bristol-ws-2025)
- Click on: `Code` \> `Download ZIP` \> unzip directory on your machine.
- Open this project by double clicking on `bristol-ws-2025.Rproj`


## Why generalised linear models?

- Unified framework of advanced statistical techniques that covers a wider range of data-analysis problems.
  - **Linear regression** and **General linear models**
  - **Generalised linear models**: transformation allows modelling of data-types including categorical, ordinal, count data.
  - **Multi-level generalised linear models**: data with hierarchical structure (repeated measures).
- Backbone of other advanced models: machine learning, time series models, path analysis, structural equation models, factor analysis, signal detection models.



## Normal linear model (formal description)


<div style="float: left; width: 30%;">



$$
\begin{aligned}
y_i &\sim \mathcal{N}(\mu, \sigma^2)
\end{aligned}
$$
</div>

<div style="float: right; width: 65%;">
- Model of how the distribution of one variable, known as the *outcome*, varies as a function of other variables, known as *predictor*.
- Each observation $y$ is a sample (indexed by $i$) from ("$\sim$") a univariate normally distributed probability model $\mathcal{N}$.
- Greek letters are the parameters that describe this distibution: mean $\mu$ and standard deviation $\sigma^2$.
</div>



## Normal linear model (formal description)

<div style="float: left; width: 30%;">

$$
\begin{aligned}
y_i &\sim \mathcal{N}(\mu_i, \sigma^2)\\
\mu_i &= \beta_0 + \beta_1 \cdot x_{1i} \\
\end{aligned}
$$
</div>

<div style="float: right; width: 65%;">
- Linear regression equation allows decomposition: value of $\mu_i$ is a linear function of values of one (or more) predictor variable $x$.
- Intercept $\beta_0$ is "constant"
- Slope $\beta_1$ depends on predictor $x_{1i}$
- If $x_{1i}$ takes on 0, $\mu_i = \beta_0$
- If $x_{1i}$ takes on 1, $\mu_i = \beta_0 + \beta_1$
- $\beta_1$ is the difference between $x_{1i}=1$ and $x_{1i}=0$.

</div>




## Simulation of normal distributed data

We can use `lm` to implement such a model.

```{r eval = F}
model <- lm(y ~ x, data = data)
```

We can simulate data that exactly meet model assumptions (normal distribution, equal variance, independence etc.) with known model parameters.




## Simulation of normal distributed data

<div style="float: left; width: 50%;">

- `rnorm` generates unimodal, symmetrically distributed values.
- `r` in `rnorm` = random; `norm` = normal

```{r}
# Generate data
y <- rnorm(n = 1000, mean = 550, sd = 10)
```

</div>

<div style="float: right; width: 45%;">

```{r echo = F, out.width="100%"}
ggplot(data = NULL, aes(x = y)) +
  geom_histogram() +
  coord_cartesian(xlim = c(500, 600),
                  ylim = c(0, 105))
```


## Simulation of normal distributed data

<div style="float: left; width: 50%;">

- `rnorm` generates unimodal, symmetrically distributed values.
- `r` in `rnorm` = random; `norm` = normal

```{r eval = F}
# Decompose the mean
beta_0 = 500
beta_1 = 50
# Generate data
y <- rnorm(n = 1000, mean = beta_0 + beta_1, sd = 10)
```

</div>

<div style="float: right; width: 45%;">

```{r echo = F, out.width="100%"}
ggplot(data = NULL, aes(x = y)) +
  geom_histogram() +
  coord_cartesian(xlim = c(500, 600),
                  ylim = c(0, 105))
```



## Simulation of normal distributed data


```{r}
# Set parameter values
n <- 1000
beta_0 <- 500 
beta_1 <- 50
sigma <- 100
```

```{r}
# Random data for group 1
group_1 <- rnorm(n = n/2, mean = beta_0, sd = sigma)
# Random data for group 2
group_2 <- rnorm(n = n/2, mean = beta_0 + beta_1, sd = sigma)
```

```{r}
# Generate data
sim_data <- tibble(group_1 = group_1,
                   group_2 = group_2) 

# Preview data
glimpse(sim_data)
```


```{r}
# Change data format
sim_data <- pivot_longer(sim_data, cols = c(group_1, group_2), names_to = "x", values_to = "y")

# Preview data
glimpse(sim_data)
```


<!-- <div style="float: right; width: 45%;"> -->

<!-- ```{r echo = F, out.width="100%"} -->
<!-- ggplot(data = sim_data, aes(x = y, colour = x, fill = x)) + -->
<!--   geom_density(alpha = .25)  -->
<!-- ``` -->

<!-- </div> -->

## Simulation of normal distributed data

```{r}
# As a reminder, these are the parameter values
beta_0 <- 500 
beta_1 <- 50
sigma <- 100
```


`lm` uses maximum likelihood estimation to determine for which set of parameter values are the data most likely.


```{r}
# Normal linear model of simulated data
model <- lm(y ~ x, data = sim_data)

coef(model) # Model coefficients
```

```{r}
sigma(model) # Standard deviation
```


Exercise: complete script `normal_model_simulation.R`


## Real data 

- By using linear models to estimate parameter values from data we make assumptions about the process that generates the data.
- For simulated data we know the process that generated the data. 
    - normal distribution because `rnorm` samples normally distributed data
    - both groups have the same variance because `sigma` was the same.
- Even if we know that assumptions are met, parameter estimates obtained are not identical but similar to the true parameter values.
- In real life we don't know the true parameter values or the underlying process that generates the data.


# Real (hierarchical) data: @martin2010planning 


## @martin2010planning data (Experiment 3a)


```{r echo=F}
p1 <- image_read("../gfx/Martin2014stim_conjoined.png") %>% image_ggplot() +
  labs(title = "Conjoined subject NP") +
  theme(plot.title = element_text(hjust = 0.5))
p2 <- image_read("../gfx/Martin2014stim_simple.png") %>% image_ggplot() +
  labs(title = "Simple subject NP") +
    theme(plot.title = element_text(hjust = 0.5))

p1 + p2
```

```{r}
data <- read_csv("../data/martin-etal-2010-exp3a.csv")
```

```{r echo = FALSE}
data
```


```{r}
summarise(data, across(c(ppt, item), list(n = ~length(unique(.))), .names = "{col}"))
```


## Aggregation by participants (across items)

In standard repeated measures ANOVAs only one source of variance can be modelled at a time.

For example one would aggregate across items and by-participant neglecting the by-items variance.

```{r}
data_ppt <- summarise(data, rt = mean(rt), .by = c(nptype, ppt))
```

```{r echo = FALSE}
data_ppt %>% arrange(ppt)
```




## Conditions nested within participants

```{r fig.height=4, fig.width=10, echo = F}
# Parameters
n_participants <- 12

# Create the hierarchical structure
edges <- tibble::tibble(from = character(), to = character())

# Add individual participants under "Participants"
for (p in 1:n_participants) {
  edges <- edges %>%
    add_row(from = "Participants", to = paste0("P", p))
}

# Connect each individual participant to both conditions
for (p in 1:n_participants) {
  edges <- edges %>%
    add_row(from = paste0("P", p), to = "simple\nNP") %>%
    add_row(from = paste0("P", p), to = "conjoined\nNP")
}

# Convert to graph
graph <- as_tbl_graph(edges, directed = TRUE) 

# Create a layout and adjust the x-coordinates of the top nodes
layout <- create_layout(graph, layout = "auto")
layout$x[layout$name == "simple\nNP"] <- layout$x[layout$name == "simple\nNP"] - 2
layout$x[layout$name == "conjoined\nNP"] <- layout$x[layout$name == "conjoined\nNP"] + 2

ggraph(layout) +  
  geom_edge_link(aes(start_cap = label_rect(node1.name), 
                     end_cap = label_rect(node2.name))) +
  geom_node_label(aes(label = name), 
                  fill = "lightblue", 
                  color = "black", 
                  size = 4) +
  theme_void() +
  coord_cartesian(clip = 'off') 


```



## Participant variation (by-participant means)

```{r echo = F}
data_ppt %>% 
  summarise(rt = mean(rt), .by = c(nptype, ppt)) %>% 
  arrange(ppt, nptype) %>% 
  mutate(direction = case_when(diff(rt) < 0 ~ "positive",
                               TRUE ~ "negative"),
         .by = ppt) %>% 
  ggplot(aes(x = nptype, y = rt, group = ppt, colour = direction)) +
  geom_point() +
  geom_line() +
  theme(legend.position = "none")
```



## Model description

Each rt observation $i \in 1 \dots N$ comes from a normal distribution with a mean $\mu$ and a standard deviation $\sigma^2$.

$$
\text{rt}_i \sim \mathcal{N}(\mu_i, \sigma^2)\\
$$

Using the linear regression equation, the mean $\mu$ can be decomposed into

$$
\mu_i = \beta_0 + \beta_1 \cdot \text{nptype}_i + \text{ppt}_i\\
$$

where $\text{nptype}_i$ is dummy coded (by default as treatment contrast in alphabetical order) 


$$
\text{nptype}_i = \left\{ 
  \begin{array}{ll}
  0, \text{ if nptype}_i = \texttt{conjoined}\\
  1, \text{ if nptype}_i = \texttt{simple}\\
  \end{array}
\right.
$$


$\beta_0$ is the average `rt` for conjoined NPs because 

$\beta_0 + \beta_1 \cdot 0 = \beta_0$, 

the average `rt` for simple NPs is 

$\beta_0 + \beta_1 \cdot 1 = \beta_0 + \beta_1$,

and therefore $\beta_1$ is the difference in rts between conjoined and simple NPs. 

Finally $\text{ppt}_i \sim \mathcal{N}(0, \sigma^2_\text{ppt})$.


## Model implementation in R

Repeated measures ANOVA:

```{r}
library(afex)
m <- aov_car(rt ~ Error(ppt/nptype), data = data_ppt)
summary(m)
```

Linear mixed-effects model:

```{r}
library(lme4)
m <- lmer(rt ~ nptype + (1|ppt), data = data_ppt)
anova(m)
```


Exercises: complete script `repeated_measures_model.R`

and after that `mixed_effects_model.R`.


## Item variation (by-image sets means)

```{r echo = F}
data %>% 
  summarise(rt = mean(rt), .by = c(nptype, item)) %>% 
  arrange(item, nptype) %>% 
  mutate(direction = case_when(diff(rt) < 0 ~ "positive",
                               TRUE ~ "negative"),
         .by = item) %>% 
  ggplot(aes(x = nptype, y = rt, group = item, colour = direction)) +
  geom_point() +
  geom_line() +
  theme(legend.position = "none")
```


## Crossed participants and items

```{r fig.height=4, fig.width=10, echo = F}
# Parameters
n_participants <- 12
n_items <- c(1, "...", 48)

# Create the hierarchicalstructure
edges <- tibble::tibble(from = character(), to = character())

# Add individual participants under "Participants"
for (p in 1:n_participants) {
  for (i in n_items){
    edges <- edges %>%
      add_row(from = "Participants", to = paste0("[", p, ", ", i, "]")) %>% 
      add_row(from = "Items", to = paste0("[", p, ", ", i, "]"))
  }
}

# Connect each individual participant to both conditions
for (p in 1:n_participants) {
    for (i in n_items){
      edges <- edges %>%
        add_row(from = paste0("[", p, ", ", i, "]"), to = "simple\nNP") %>%
        add_row(from = paste0("[", p, ", ", i, "]"), to = "conjoined\nNP")
    }
}

# Convert to graph
graph <- as_tbl_graph(edges, directed = TRUE) 

# Create a layout and adjust the x-coordinates of the top nodes
layout <- create_layout(graph, layout = "auto")
layout$x[layout$name == "Participants"] <- layout$x[layout$name == "Participants"] - 8
layout$x[layout$name == "Items"] <- layout$x[layout$name == "Items"] + 8
layout$x[layout$name == "simple\nNP"] <- layout$x[layout$name == "simple\nNP"] - 8
layout$x[layout$name == "conjoined\nNP"] <- layout$x[layout$name == "conjoined\nNP"] + 8

ggraph(layout) +  
  geom_edge_link(aes(start_cap = label_rect(node1.name), 
                     end_cap = label_rect(node2.name))) +
  geom_node_label(aes(label = name), 
                  fill = "lightblue", 
                  color = "black", 
                  size = 3) +
  theme_void() +
  coord_cartesian(clip = 'off') 

```



## What's a mixed-effects model?

- Combination of fixed and random effects
- Allows to address dependency in the data: hierarchical (nested, multi-level) and crossed factor
- Fixed effects: systematic / deterministic effects (e.g. age, trial id, grouping variables)
- Random effects: non-systematic effects (e.g. ppts, items, class, country)
- Random effects can be nested: people within country; students within classroom within school within area etc.
- Sometimes the differences can be blurry: comparing differences between two test sites rather than treating test sites as repeated measures variable.




## Crossed participants and items

- Traditional repeated-measures ANOVA can only handle one source of variance (participant or item).
- Linear mixed-effects models can capture one and more [@baayen2008mixed].


```{r eval = F}
m <- lmer(rt ~ nptype + ( 1 | ppt ) + ( 1 | item ), data = data)
```

```{r eval = T, echo = F}
m <- lme4::lmer(rt ~ nptype + (1|ppt) + (1|item), data = data)
```



## Crossed participants and items

```{r}
summary(m)$varcor
```

```{r}
sigma(m)
```


## Random intercepts

```{r echo=F, fig.width=10}
ri_ppt <- ranef(m)$ppt %>% 
  as.data.frame() %>% 
  rownames_to_column("ppt") %>% 
  mutate(across(`(Intercept)`, ~m@beta[1] + .))

ri_items <- ranef(m)$item %>% 
  as.data.frame() %>% 
  rownames_to_column("items") %>% 
  mutate(across(`(Intercept)`, ~m@beta[1] + .))

# Plot for Subject random intercepts
p1 <- ggplot(ri_ppt, aes(x = reorder(ppt, `(Intercept)`), y = `(Intercept)`, label = ppt)) +
    geom_label() +
    geom_hline(yintercept = m@beta[1], linetype = "dashed") +
    labs(x = "",
         subtitle = "Participants",
         y = "Random Intercept") +
    coord_flip() +
    theme(axis.text.y = element_blank(),
          axis.ticks.y = element_blank())

# Plot for Group random intercepts
p2 <- ggplot(ri_items, aes(x = reorder(items, `(Intercept)`), y = `(Intercept)`, label = items)) +
    geom_label(size = 2) +
    geom_hline(yintercept = m@beta[1], linetype = "dashed") +
    labs(x = "",
         subtitle = "Items",
         y = "Random Intercept") +
    coord_flip() +
    theme(axis.text.y = element_blank(),
          axis.ticks.y = element_blank())


# Display the plots
p1 + plot_spacer() + p2 + plot_layout(widths = c(.45, .05, .45))
```



## Predicted outcomes

```{r}
summary(m)$coef
```

```{r}
(coefs <- m@beta) # extract estimates
```


```{r}
# Predicted mean for np conjoined
coefs[1] + coefs[2] * 0
```

```{r}
# Predicted mean for np simple
coefs[1] + coefs[2] * 1
```


```{r}
# Check predictor contrasts (default: treatment)
contrasts(factor(data$nptype))
```


## Null-hypothesis test for `lmer` models?


*t*-values $> \mid 2 \mid$ correspond to $\alpha = .05$ [@baa08book]:

```{r}
summary(m)$coef
```

Confidence intervals: 95% CI shows the range of hypotheses that can't be ruled out for $\alpha = .05$:

```{r}
confint(m, "nptypesimple")
```

Satterthwaite approximation for degrees of freedom (`lmerTest`):

```{r}
m <- lmerTest::lmer(rt ~ nptype + ( 1 | ppt ) + ( 1 | item ), data = data)
summary(m)$coef
```

Likelihood-ratio test:

```{r}
m_null <- lmer(rt ~ 1 + ( 1 | ppt ) + ( 1 | item ), data = data)
anova(m_null, m)
```





## Predicted effects by participants and items

```{r echo = F}
data_pred <- expand.grid(item = 1:48, ppt = 1:12, nptype = unique(data$nptype)) %>% 
  mutate(pred = predict(m, newdata = .),
         m = "random intercepts")
```

```{r fig.width=10, fig.height = 8, echo = F}
ggplot(data_pred, aes(x = nptype, y = pred, group = item)) +
  geom_point(size = .1) +
  geom_line(linewidth = .1) +
  theme_bw(base_size = 11) +
  facet_wrap(~ppt, scales = "free", labeller = label_both, ncol = 4) +
  labs(y = "predicted rt", caption = "Lines represent items")
```

## Random intercepts and random slopes

- Random intercepts: size of np-type effect is constant.
- Random slopes: size of np-type effect varies by participants and items.
- Correlation between random intercepts and random slopes: e.g. np-type effect might be weaker for participants / items with longer rts.
- Maximal random effects structure [@barr2013random]: for repeated-measures designs with crossed participants and items, we need random intercepts for participants and items with by-participants and by-items random slopes.


```{r}
# Random intercepts model
m <- lmer(rt ~ nptype + ( 1 | ppt ) + ( 1 | item ), data = data)

# Maximal random effects structure 
m_max <- lmer(rt ~ nptype + ( nptype | ppt ) + ( nptype | item ), data = data)

```

```{r echo = F}
data_pred_cor <- expand.grid(item = 1:48, ppt = 1:12, nptype = unique(data$nptype)) %>% 
  mutate(pred = predict(m_max, newdata = .),
         m = "with correlation")
```


## Random intercepts and random slopes

```{r fig.width=8, fig.height=4.5, echo = F}
bind_rows(data_pred, data_pred_cor) %>% 
  filter(ppt %in% c(7, 11)) %>% 
  mutate(across(m, ~case_when(str_detect(., "intercepts") ~ "\n( 1 | ppt ) + ( 1 | item )",
                              str_detect(., "without") ~ "\n(nptype||ppt) + (nptype||ppt)",
                              str_detect(., "with ") ~ "\n( nptype | ppt ) + ( nptype | item )"))) %>% 
  rename(`random effects` = m) %>% 
  ggplot(aes(x = nptype, y = pred, group = item)) +
  geom_point(size = .1) +
  geom_line(linewidth = .1) +
  theme_bw(base_size = 11) +
  facet_grid(ppt ~ `random effects`, scales = "free", labeller = label_both) +
  labs(y = "predicted rt", caption = "Lines represent items")

```

## Model summary

```{r}
# Maximal random effects model 
summary(m_max)
```



## Hypothetical examples {.smaller}

Task: Pair designs with their maximal random-effects structure!

- Design 1 (between participants / within items): both NP type conditions were presented for each item set but half of the participants saw simple NPs and the other half saw conjoined NPs.
- Design 2 (within participants / within items): each participant saw both conditions and each item was presented in both conditions.
- Design 3 (within participants / between items): half of all items were conjoined and the other half were simple NP type; each participant saw both condition (simple NPs and conjoined NPs).
- Design 4 (between participants / between items): half of all items were conjoined and half were simple NP type; half of the participants saw simple NPs and the other half saw conjoined NPs.


```{r eval=F}
Model_A <- lmer(rt ~ nptype + ( 1 | ppt ) + ( nptype | item ), data = data) 
Model_B <- lmer(rt ~ nptype + ( 1 | ppt ) + ( 1 | item ), data = data)
Model_C <- lmer(rt ~ nptype + ( nptype | ppt ) + ( nptype | item ), data = data) 
Model_D <- lmer(rt ~ nptype + ( nptype | ppt ) + ( 1 | item ), data = data) 
```

Exercise: complete exercise script `mixed_effects_model_rirs.R`




## Generalised linear models {.smaller}

Type of outcome variable

Continuous: 

```{r eval = F}
library(lme4)
model <- lmer(dv ~ iv + ( random slopes | random intercepts ), data = data)
```

Binary: 

```{r eval = F}
library(lme4)
model <- glmer(dv ~ iv + ( random slopes | random intercepts ), data = data, family = binomial())
```

Count: 

```{r eval = F}
library(lme4)
model <- glmer(dv ~ iv + ( random slopes | random intercepts ), data = data, family = poisson())
```


Also negative-binomial `lme4::glmer.nb` and zero-inflated count models `NBZIMM::glmm.zinb`.

Ordinal: 

```{r eval = F}
library(ordinal)
model <- clmm(dv ~ iv + ( random slopes | random intercepts ), data = data)
```

Frequentist mixed-effects models require familiarity with different packages.


## Convergence failures {.columns-2}

- Maximal random effects structure were introduced as gold-standard for repeated-measures experiments [@barr2013random; @baayen2008mixed].
- Easy to fit for simple designs with balanced samples and simulations [@barr2013random].
- Convergence failures are well documented in the literature [@bates2015parsimonious; @eager2017mixed; @kimball2016beyond].

\

- Overparameterisation: unidentifiable parameter estimates [@bates2015parsimonious].
- `lme4` author Bates proposed the use of "parsimonious" random-effects structures [@bates2015parsimonious].
- Model selection based on failure to fit more complex model.


## Alternative 

- Convergence failures (and other problems like floor and ceiling effects) can be (easily) addressed in Bayesian models.
- Bayesian model converge *by definition* (as the number of iterations approaches $\infty$).


# Fitting mixed-effects models in `brms` | [@burkner2017brms; @brms2]

## `brms` [@burkner2017brms]  {.columns-2 .smaller}

- *R* package for Bayesian models
- (Almost) no more complicated to fit than `lme4` models.
- Syntax deliberately mimics `lme4`.
- More probability models than other packages: `gaussian`, `lognormal`, `bernoulli`, `poisson`, `zero_inflated_poisson`, `skew_normal`, `shifted_lognormal`, `exgaussian`, *et cetera*
- Allows mixture models, nonlinear syntax, (un)equal variance signal-detection theory, multivariate models
  
\

- More flexibility is only with Stan [@annis2017bayesian; @carpenter2017stan].
- `brms` creates Stan code to compile a probabilistic MCMC (Markov Chain Monte Carlo) sampler.
- Compiling the sampler and obtaining the full posterior can take time.

Exercise: complete script `mixed_effects_model_brms.R`


## *R* syntax

Frequentist mixed-effects models

```{r eval=T}
library(lme4)
fit_lmer <- lmer(rt ~ nptype + ( nptype | ppt ) + ( nptype | item ), data = data)
```

Bayesian mixed-effects models

```{r eval=F}
library(brms)
fit_brm <- brm(rt ~ nptype + ( nptype | ppt ) + ( nptype | item ), data = data)
```

```{r eval = T, echo = F}
fit_brm <- readRDS(file = "../models/fit_brm.rds")
```


## Fit models on simulated data

<div style="float: left;width: 75%">

```{r echo = T}
coef(summary(fit_lmer)) # Coefficients of frequentist model
```


```{r echo = T}
fixef(fit_brm) # Coefficients of Bayesian model
```

</div>




# Why Bayesian? | see e.g. @kruschke2014doing 


## Two universes

Two different philosophical frameworks of generalising from sample to the population: What do the data tell us about "the truth"?

- **Null-hypothesis significance testing**
- **Bayesian inference**





## Null-hypothesis significance testing 

- Classical / frequentist statistics; *p*-value based statistics
- *p*-value: How plausible are the data (or something more extreme) if we assume that there's no effect?
- Evaluating the probability of data (e.g. *t*-value, *F*-statistic) assuming that the null hypothesis $H_0$ is true.
- If the data are extreme enough, $H_0$ is concluded to be implausible (rejected).
- If $H_0$ is implausible, we assume $H_1$ (alternative hypothesis).
- *Statistically significant* means data are unexpected under $H_0$.

$$
Pr(\text{data} \mid H_0 = \text{TRUE})
$$



## Its problems {.columns-2}

- Focus on significance: small effects can become significant when the sample is large enough.
- People think of statistical significance as continuous not binary.
- How often do we actually believe in $H_0$?
- What are you doing if $p=0.051$? 
    
<!-- - This seems even worse in reality [@amrhein2019inferential;@loken2017measurement] -->

\

- Systematic misinterpretations of *p*-values [@colquhoun2017reproducibility; @greenland2016statistical] and CIs [@hoekstra2014robust; @morey2016fallacy]
- Optional stopping [@kruschke2018rejecting]
- $\alpha$-level of 0.05 implies there is a 5% chance that:
    - our effect isn't real. 
    - we'll miss an effect that is real.



## Bayesian inference

- Expressing uncertainty about a hypothesis expressed in probability distributions
- Updating one's belief (prior, example later) about a hypothesis (e.g. difference between conditions, interactions etc) as the new information becomes available.

$$
Pr(H \mid \text{data})
$$


## Bayes' Theorem 

$$
\underbrace{Pr(\theta \mid \text{data})}_{\text{posterior}} \propto \underbrace{Pr(\theta)}_{\text{prior}} \cdot \underbrace{Pr(\text{data} \mid \theta)}_{\text{likelihood}}
$$

- Likelihood: probability of data given the model parameter value(s) 
- Prior: what do we already know about model parameter(s)
- Posterior: our updated belief in the parameter value(s) after seeing the data



## Why is Bayesian inference important?

> Instead of concluding

\

$$
Pr(\text{data} \mid H_0 = \text{TRUE})
$$

> we can answer

\

$$
Pr(H \mid \text{data})
$$




## Why is Bayesian inference important?

It tells us what we want to know!

\

- What's the probability of an effect given the data (and what we already knew before)?
- Summary stats of a Bayesian model are often very similar to what people *think* frequentist quantities (*p*-values, CIs) mean [@nicenboim2016statistical]:
- What's the relative evidence for one model (e.g., $H_0$) vs. another (e.g., $H_1$)?
- What interval contains an unknown parameter value with .95 probability?
<!-- - Results are not dependent on sampling plan [@kruschke2018rejecting]. -->




## Why is Bayesian inference important?

- Estimate the posterior uncertainty over parameter values based on the observed data [@kruschke2014doing].
- For this we need 

1. a probability model (e.g. a normal distribution and a set of predictors)
2. *priors* (on e.g. means, difference, variability)

- `brms` uses probabilistic sampling to determine the posterior uncertainty about the parameter value.
- This involve calculating the weighted probability of the likelihood of the data given a proposed parameter value in the (potentially high dimensional) parameter space.
- This can take time.




# Convergence and model diagnostics | see @lambert2018student for HMC


## So what about this? {.smaller}

<div style="float: left;width: 55%">

![](../gfx/sampling.png){width=100%}
</div>

<div style="float: right;width: 40%">

Progress of probabilistic sampler.

By default:

- 2,000 iterations for parameter estimation per chain 
- `iterations / 2` warm-up samples: discarded eventually 
- 4 chains to establish convergence
- How many posterior samples have we got for inference (`= chains * (iterations - warm-up)`)?
- How many iterations / chains do you need?

</div>



## Parameter estimation

<div style="float: left;width: 40%">

- **Hamiltonian Monte Carlo:** Markov chain Monte Carlo method for obtaining random samples.
- Likelihood of random samples is estimated given the data and the prior.
- Direction changes if probability of proposed estimate is lower than previous one.

</div>

<div style="float: right;width: 55%">

```{r echo = F}
sim <- fit_brm$fit@sim
samples <- map(1:4, ~sim$samples[[.]] %>%
                 as_tibble() %>%
      select(starts_with("b")) %>%
      mutate(chain = .x,
             iteration = 1:n())) %>% bind_rows() %>%
    pivot_longer(starts_with("b")) %>%
  mutate(name = factor(name, levels = unique(name)[c(1,2)], ordered = T),
         chain = factor(chain))
```

```{r fig.width=5, echo = F}
pivot_wider(samples, names_from = name, values_from = value) %>%
  filter(chain == 1) %>%
  mutate(chain = paste0("Chain: ", chain)) %>%
  ggplot(aes(x = b_Intercept, y = b_nptypesimple, colour = chain)) +
  scale_color_viridis_d("") +
  geom_path(show.legend = F, colour =  "white") +
  facet_wrap(~chain) +
  labs(title = "Parameter space") +
  scale_x_continuous(limits = c(-100, 1300), breaks = seq(-150, 1600, 250)) +
  scale_y_continuous(limits = c(-150, 100), breaks = seq(-150, 600, 50)) +
  theme(legend.justification = "top")
```

</div>


## Parameter estimation

<div style="float: left;width: 40%">


- **Hamiltonian Monte Carlo:** Markov chain Monte Carlo method for obtaining random samples.
- Likelihood of a random sample is estimated given the data and the prior.
- Direction changes if probability of proposed sample is lower than previous one.


</div>

<div style="float: right;width: 55%">

```{r fig.width=5, echo = F}
pivot_wider(samples, names_from = name, values_from = value) %>%
  filter(chain == 1) %>%
  mutate(chain = paste0("Chain: ", chain)) %>%
  ggplot(aes(x = b_Intercept, y = b_nptypesimple, colour = chain, alpha = iteration, label = iteration)) +
  scale_color_viridis_d("") +
  geom_path(show.legend = F) +
  geom_text(show.legend = F, size = 2, aes(alpha = -iteration)) +
  facet_wrap(~chain) +
  labs(title = "Parameter space") +
  scale_x_continuous(limits = c(-100, 1300), breaks = seq(-150, 1600, 250)) +
  scale_y_continuous(limits = c(-150, 100), breaks = seq(-150, 600, 50)) +
  theme(legend.justification = "top")
```

</div>



## Parameter estimation (traceplot)

```{r echo =F}
samples %>%
  filter(chain %in% 1, iteration %in% 1:100) %>%
  ggplot(aes(y=value, x = iteration, colour = chain)) +
  scale_color_viridis_d("Chains") +
  geom_path() +
  facet_wrap(~name, scales = "free") 
```


## Parameter estimation (traceplot)

```{r echo = F}
samples %>%
  filter(chain %in% 1:2, iteration %in% 1:100) %>%
  ggplot(aes(y=value, x = iteration, colour = chain)) +
  scale_color_viridis_d("Chains") +
  geom_path() +
  facet_wrap(~name, scales = "free") 
```


## Parameter estimation (traceplot)

```{r echo =F}
samples %>%
  filter(chain %in% 1:4, iteration %in% 1:100) %>%
  ggplot(aes(y=value, x = iteration, colour = chain)) +
  scale_color_viridis_d("Chains") +
  geom_path() +
  facet_wrap(~name, scales = "free") 
```


## Parameter estimation (traceplot)

```{r echo = F}
samples %>%
  filter(chain %in% 1:4, iteration %in% 1:250) %>%
  ggplot(aes(y=value, x = iteration, colour = chain)) +
  scale_color_viridis_d("Chains") +
  geom_path() +
  facet_wrap(~name, scales = "free")
```

## Parameter estimation (traceplot)

```{r echo=F}
samples %>%
  filter(chain %in% 1:4, iteration %in% 1:500) %>%
  ggplot(aes(y=value, x = iteration, colour = chain)) +
  scale_color_viridis_d("Chains") +
  geom_path() +
  facet_wrap(~name, scales = "free") 
```


## Parameter estimation (traceplot)

```{r echo = F}
samples %>%
  filter(chain %in% 1:4, iteration %in% 1:2000) %>%
  ggplot(aes(y=value, x = iteration, colour = chain)) +
  scale_color_viridis_d("Chains") +
  geom_path() +
  facet_wrap(~name, scales = "free") 
```

## Parameter estimation (traceplot)

```{r echo = F}
samples %>%
  filter(chain %in% 1:4, iteration %in% 1000:2000) %>%
  ggplot(aes(y=value, x = iteration, colour = chain)) +
  scale_color_viridis_d("Chains") +
  geom_path() +
  facet_wrap(~name, scales = "free") 
```

## Model diagnostics and convergence checks

<div style="float: left;width: 50%">

- Traceplots: we want fat hairy caterpillars 
- $\hat{R}$ convergence statistic; should be $<1.1$ [@gelman1992]
- Posterior predictive checks: compare data $y$ and predictions $y_{rep}$
- Exercise: complete script `model_diagnostics.R` 

</div>

<div style="float: right;width: 45%">
```{r echo = F, out.width="400px", out.height="400px"}
include_graphics("../gfx/caterpillar.jpeg")
```
</div>


# Where are the priors? | see e.g. chapter 7 in @lee2014bayesian



## Priors

- Prior knowledge about plausible parameter values.
- This knowledge is expressed as probability distributions (e.g. normal distributions).
- Help probabilistic sampler by limiting the parameter space.
- Small data samples are sensitive to prior information which makes intuitively sense.
- Otherwise data typically overcome the prior (automatic Ockham's razor).
- Less common: test data against a (prior) effect suggested by the literature.


## Priors: intercept

<div style="float: left;width: 40%;">

- *A priori*, each value in the parameter space is equally possible. 
- Let's think about the parameter space for rts.

</div>

<div style="float: right;width: 50%;">

```{r fig.width=5, echo = F}
tibble(intercept = runif(1000, 0, 5000),
       slope = runif(1000,  -10000, 10000)) %>%
  ggplot(aes(x=intercept, y=slope)) +
  labs(subtitle = "Parameter space")
```
</div>



## Priors: intercept

<div style="float: left;width: 40%;">

- Can rts range between -$\infty$ and $\infty$? 
- What are plausible lower and upper end?
- Plausible probability distribution for rts:

$$
\beta_0 \sim \mathcal{N}(1000 \text{ msecs}, ???)
$$

</div>




<div style="float: right;width: 50%;">

```{r fig.width=5, echo = F}
tibble(intercept = runif(1000, 0, 5000),
       slope = runif(1000,  -10000, 10000)) %>%
  ggplot(aes(x=intercept, y=slope)) +
  labs(subtitle = "Parameter space")
```

</div>





## Priors: intercept

<div style="float: left;width: 40%;">


- Can rts range between -$\infty$ and $\infty$? 
- What are plausible lower and upper end?
- Plausible probability distribution for rts:
  
$$
\beta_0 \sim \mathcal{N}(1000 \text{ msecs}, 150\text{ msecs})
$$

</div>


<div style="float: right;width: 50%;">

```{r fig.width=5, echo = F}
p <- tibble(intercept = rnorm(10000, mean = 1000, sd = 150),
       slope = runif(10000,  -10000, 10000)) %>%
  ggplot(aes(x=intercept, y=slope)) +
    geom_point(size = .25, colour = "transparent") + 
  geom_density_2d_filled(alpha = 0.25, show.legend = F) +
  geom_density_2d(alpha = 0.5, show.legend = F, size = .15, color = "black") +
  scale_fill_viridis_d(direction = -1, begin = 0, end = .6) +
  scale_x_continuous(limits = c(0, 5000)) +
  labs(subtitle = "Parameter space")

ggExtra::ggMarginal(p, type="density", size=10, alpha = .25, margins = "x")
```

</div>


## Priors: slope

<div style="float: left;width: 50%;">

- What do we know about the difference between simple and conjoined NPs?
- Let's pretend we don't know much: so a priority there might be a mean difference of 0 msecs.
- How large are rt differences usually? Anything larger than 200 msecs would be massive, so lets propose a humble standard deviation of 100 msecs

$$
\beta_1 \sim \mathcal{N}(0\text{ msecs}, 100\text{ msecs})
$$
</div>

<div style="float: right;width: 50%;">

```{r fig.width=5, echo = F}
p <- tibble(intercept = rnorm(10000, mean = 1000, sd = 150),
       slope = runif(10000,  -10000, 10000)) %>%
  ggplot(aes(x=intercept, y=slope)) +
    geom_point(size = .25, colour = "transparent") + 
  geom_density_2d_filled(alpha = 0.25, show.legend = F) +
  geom_density_2d(alpha = 0.5, show.legend = F, size = .15, color = "black") +
  scale_fill_viridis_d(direction = -1, begin = 0, end = .6) +
  scale_x_continuous(limits = c(0, 10000)) +
  labs(subtitle = "Parameter space")

ggExtra::ggMarginal(p, type="density", size=10, alpha = .25, margins = "x")
```

</div>



## Priors: slope

<div style="float: left;width: 50%;">

- What do we know about the difference between simple and conjoined NPs?
- Let's pretend we don't know much: so a priority there might be a mean difference of 0 msecs.
- How large are rt differences usually? Anything larger than 200 msecs would be massive, so lets propose a humble standard deviation of 100 msecs

$$
\beta_1 \sim \mathcal{N}(0\text{ msecs}, 100\text{ msecs})
$$
</div>

<div style="float: right;width: 50%;">

```{r fig.width=5, echo = F}
p <- tibble(intercept = rnorm(10000, mean = 1000, sd = 150),
       slope = rnorm(10000,  0, 100)) %>%
  ggplot(aes(x=intercept, y=slope)) +
    geom_point(size = .25, colour = "transparent") + 
  geom_density_2d_filled(alpha = 0.25, show.legend = F) +
  geom_density_2d(alpha = 0.5, show.legend = F, size = .15, color = "black") +
  scale_fill_viridis_d(direction = -1, begin = 0, end = .6) +
  scale_x_continuous(limits = c(0, 5000)) +
  scale_y_continuous(limits = c(-300,1000), breaks = seq(-300, 900, 250)) +
  labs(subtitle = "Parameter space")
ggExtra::ggMarginal(p, type="density", size=10, alpha = .25, margins = "both")
```

</div>


## Priors

- `brms` uses default priors that can be changed as appropriate. 
- Some defaults are good, `(flat)` priors are worth specifying.

Check defaults used earlier:


```{r echo = T, eval = F}
prior_summary(fit_brm)
```

```{r echo = F, eval = T}
prior <- get_prior(fit_brm$formula, fit_brm$data) # %>% as_data_frame() %>% select(-source)
prior %>% as_tibble() %>%
  mutate(prior = ifelse(class == "b", "(flat)", prior),
         prior = ifelse(prior == "", unique(prior)[!unique(prior) == ""], prior),
         .by = class) %>%
  select(prior:group) %>% kable() %>%
  kable_styling("striped", full_width = F, font_size = "small") %>%
  column_spec(1, width = "20em") %>%
  column_spec(2:4, width = "10em") 
```


\

```{r fig.width=5, echo = F, fig.align='center'}
p <- tibble(intercept = rstudent_t(10000, 3, 1039.5, 235),
       slope = runif(10000, -2000, 2000)) %>%
  ggplot(aes(x=intercept, y=slope)) +
    geom_point(size = .25, colour = "transparent") + 
  geom_density_2d_filled(alpha = 0.25, show.legend = F) +
  geom_density_2d(alpha = 0.5, show.legend = F, size = .15, color = "black") +
  scale_fill_viridis_d(direction = -1, begin = 0, end = .6) +
  scale_x_continuous(limits = c(0, 5000)) +
  scale_y_continuous(limits = c(-1000, 1000), breaks = seq(-1000, 1000, 250)) +
  labs(subtitle = "Parameter space")
ggExtra::ggMarginal(p, type="density", size=10, alpha = .25, margins = "both")
```



Exercise: complete script `mixed_effects_model_brms_with_priors.R` (this time with priors)



# Hypothesis testing | see e.g. @nicenboim2016statistical for a tutorial

## What results do I report?

- To test a hypothesis about parameter values (e.g. difference between groups, interactions, change in outcome):
  - Summary of posterior parameter value
  - Region of practical equivalence (ROPE)
  - Savage-Dickey Bayes Factor: for nested models
- Cross-validation (leave-one-out): comparison of different probability models

## Posterior probability distribution

Get posterior of slope $\beta$ (difference between conditions)

```{r echo = T}
beta <- as_draws_df(fit_brm) %>% pull(b_nptypesimple)
```


```{r echo = T}
length(beta)
```


```{r echo = T}
beta[1:5]
```


## Posterior probability distribution


<div style="float: right;width: 55%">

```{r fig.height=4.5, fig.width=5.5, echo = F}
ggplot(data = NULL, aes(x = beta)) +
  geom_histogram(alpha = .55) +
  labs(x = bquote("Estimated effect"~hat(beta)))
```

</div>

## Posterior probability distribution

<div style="float: left;width: 45%">

Posterior mean

```{r echo = T}
mean(beta)
```

</div>

<div style="float: right;width: 55%">

```{r fig.height=4.5, fig.width=5.5, echo = F}
ggplot(data = NULL, aes(x = beta)) +
  geom_histogram(alpha = .55) +
  labs(x = bquote("Estimated effect"~hat(beta))) +
  geom_vline(xintercept = mean(beta), color = "darkred")
```
</div>


## Posterior probability distribution

<div style="float: left;width: 45%">

95% probability interval (conceptually different from confidence interval)

```{r echo = T}
quantile(beta, probs = c(0.025, 0.975))
```


</div>

<div style="float: right;width: 55%">

```{r fig.height=4.5, fig.width=5.5, echo = F}
ggplot(data = NULL, aes(x = beta)) +
  geom_histogram(alpha = .55, bins = 50, position = "identity", show.legend = F) +
  labs(x = bquote("Estimated effect"~hat(beta))) +
  geom_errorbarh(aes(y = 50, xmin = quantile(beta, probs = c(0.025))
, xmax =  quantile(beta, probs = c(0.975))), color = "darkred", size = 1.5, ) +
  annotate("text", x = 15, y = 55, label = "95% PI", colour = "darkred")
```
</div>

## Posterior probability distribution

<div style="float: left;width: 45%">

95% probability interval (conceptually different from confidence interval)

```{r echo = T}
quantile(beta, probs = c(0.025, 0.975))
```

89% probability interval [@mcelreath2020statistical]

```{r echo = T}
quantile(beta, probs = c(0.055, 0.945))
```

</div>

<div style="float: right;width: 55%">

```{r fig.height=4.5, fig.width=5.5, echo = F}
ggplot(data = NULL, aes(x = beta)) +
  geom_histogram(alpha = .55, bins = 50, position = "identity", show.legend = F) +
  labs(x = bquote("Estimated effect"~hat(beta))) +
  geom_errorbarh(aes(y = 75, xmin = quantile(beta, probs = c(0.055))
, xmax =  quantile(beta, probs = c(0.945))), color = "darkred", size = 1.5, ) +
  annotate("text", x = 15, y = 90, label = "89% PI", colour = "darkred")
```
</div>


## Posterior probability distribution

<div style="float: left;width: 45%">

Probability that slope $\beta$ is negative: $P(\hat{\beta}<0)$

```{r echo = T}
mean(beta < 0)
```


</div>

<div style="float: right;width: 55%">

```{r fig.height=4.5, fig.width=5.5, echo = F}
ggplot(data = NULL, aes(x = beta, fill = beta > 0)) +
  geom_histogram(alpha = .55, bins = 50, position = "identity", show.legend = F) +
  scale_fill_manual(values = c("darkred", "grey")) +
  geom_vline(xintercept = 0, colour = "grey20", linetype = "dotted") +
  labs(x = bquote("Estimated effect"~hat(beta))) 
```
</div>


## Posterior probability distribution

<div style="float: left;width: 45%">

Probability that slope $\beta$ is negative: $P(\hat{\beta}<0)$

```{r echo = T}
mean(beta < -10)
```

See exercises: `hypothesis_testing_post.R`

</div>


<div style="float: right;width: 55%">

```{r fig.height=4.5, fig.width=5.5, echo = F}
ggplot(data = NULL, aes(x = beta, fill = beta > -10)) +
  geom_histogram(alpha = .55, bins = 50, position = "identity", show.legend = F) +
  scale_fill_manual(values = c("darkred", "grey")) +
  geom_vline(xintercept = -10, colour = "grey20", linetype = "dotted") +
  labs(x = bquote("Estimated effect"~hat(beta))) 
```
</div>




# ROPE | e.g. @kruschke2010believe

## ROPE


<div style="float: left;width: 40%">

```{r}
mean(beta < 0)
```

```{r}
mean(beta < -5)
```

```{r}
mean(beta < -10)
```


There is nothing special about 0.

</div>

<div style="float: right;width: 55%">

```{r fig.height=4.5, fig.width=5.5, echo = F}
ggplot(data = NULL, aes(x = beta, fill = beta > -10)) +
  geom_histogram(alpha = .55, bins = 50, position = "identity", show.legend = F) +
  geom_vline(xintercept = -10, colour = "grey20", linetype = "dotted") +
  scale_fill_manual(values = c("darkred", "grey")) +
  labs(x = bquote("Estimated effect"~hat(beta))) 
```
</div>




## ROPE

<div style="float: left;width: 55%">

- Point values don't represent our beliefs about the null hypothesis: $H_0 = 0$
- Region of practical equivalence: range of values that are equivalent to a null effect [@kruschke2010believe; @kruschke2011bayesian].
- Define region that is equivalent to no effect: values in interval of [-10, 10] msecs

</div>

<div style="float: right;width: 45%">

```{r fig.height=4.5, fig.width=4.5, echo = F}
ggplot(data = NULL, aes(x = beta)) +
  geom_histogram(alpha = .55, bins = 50, position = "identity", show.legend = F) +
  labs(x = bquote("Estimated effect"~hat(beta))) 
```
</div>


## ROPE

<div style="float: left;width: 55%">

- Point values don't represent our beliefs about the null hypothesis: $H_0 = 0$
- Region of practical equivalence: range of values that are equivalent to a null effect [@kruschke2010believe; @kruschke2011bayesian].
- Define region that is equivalent to no effect: values in interval of [-10, 10] msecs


```{r echo = T}
library(bayestestR)
rope(beta, range = c(-10, 10)) 
```
</div>

<div style="float: right;width: 45%">

```{r fig.height=4.5, fig.width=4.5, echo = F}
ggplot(data = NULL, aes(x = beta)) +
  geom_histogram(alpha = .55, bins = 50, position = "identity", show.legend = F) +
  labs(x = bquote("Estimated effect"~hat(beta))) 
```
</div>

  
  
## ROPE
  
<div style="float: left;width: 55%">
  
- Point values don't represent our beliefs about the null hypothesis: $H_0 = 0$
- Region of practical equivalence: range of values that are equivalent to a null effect [@kruschke2010believe; @kruschke2011bayesian].
- Define region that is equivalent to no effect: values in interval of [-10, 10] msecs



```{r echo = T}
library(bayestestR)
rope(beta, range = c(-10, 10)) 
```
</div>


<div style="float: right;width: 45%">

```{r fig.height=4.5, fig.width=4.5, echo = F}
ggplot(data = NULL, aes(x = beta, fill = beta > -10 & beta < 10)) +
  geom_histogram(alpha = .55, bins = 50, position = "identity", show.legend = F) +
  geom_vline(xintercept = 10, colour = "grey20", linetype = "dotted") +
  geom_vline(xintercept = -10, colour = "grey20", linetype = "dotted") +
  scale_fill_manual(values = c("grey", "darkred")) +
  labs(x = bquote("Estimated effect"~hat(beta))) 
```
</div>


## ROPE

<div style="float: left;width: 55%">

- Point values don't represent our beliefs about the null hypothesis: $H_0 = 0$
- Region of practical equivalence: range of values that are equivalent to a null effect [@kruschke2010believe; @kruschke2011bayesian].
- Define region that is equivalent to no effect: values in interval [-10, Inf] 

```{r echo = T}
library(bayestestR)
rope(beta, range = c(-10, Inf))
```
</div>
  
  
  
<div style="float: left;width: 45%">
  
```{r fig.height=4.5, fig.width=4.5, echo = F}
ggplot(data = NULL, aes(x = beta, fill = beta > -10 & beta < Inf)) +
  geom_histogram(alpha = .55, bins = 50, position = "identity", show.legend = F) +
  geom_vline(xintercept = -10, colour = "grey20", linetype = "dotted") +
  scale_fill_manual(values = c("grey", "darkred")) +
  labs(x = bquote("Estimated effect"~hat(beta))) 
```
</div>
  
  
  
  
## ROPE
  
- Determine ROPE to assess the uncertainty of effect size [@makowski2019bayestestr]
- Calculate the standardised effect size $\delta$ from posterior: $\delta = \frac{\beta}{\sigma}$ 
- ROPE of [-0.1, 0.1] is the range of negligible effect sizes [@cohn1988statistical; @kruschke2018rejecting]. 

## ROPE


- Determine ROPE to assess the uncertainty of effect size [@makowski2019bayestestr]
- Calculate the standardised effect size $\delta$ from posterior: $\delta = \frac{\beta}{\sigma}$ 
- ROPE of [-0.1, 0.1] is the range of negligible effect sizes [@cohn1988statistical; @kruschke2018rejecting]. 

```{r echo = T}
sigma <- as_draws_df(fit_brm) %>% pull(sigma)
delta <- beta / sigma
```

```{r echo = T}
abs(mean(delta)) # very small effect (see Cohen's d)
```

## ROPE

- Determine ROPE to assess the uncertainty of effect size [@makowski2019bayestestr]
- Calculate the standardised effect size $\delta$ from posterior: $\delta = \frac{\beta}{\sigma}$ 
- ROPE of [-0.1, 0.1] is the range of negligible effect sizes [@cohn1988statistical;@kruschke2018rejecting]. 

```{r echo = T}
rope(delta, range = c(-0.1, 0.1)) 
```


## ROPE

- The ROPE value indicates the extent to which the posterior cannot rule out a negligible effect. 
- A meaningful effect size should have a small proportion of posterior samples within the ROPE. 

```{r echo = T}
rope(delta, range = c(-0.1, 0.1)) 
```


Exercise: complete script `hypothesis_testing_rope.R`



# Bayes Factor | e.g. chapter 7.6 in @lee2014bayesian


## Bayes Factor

<div style="float: left;width: 60%;">

*p*-values have two possible outcomes: 

1. reject the null (i.e. $p<0.05$)
2. inconclusive (i.e. $p>0.05$ -- go back to start)

BFs have a continuum of three possible outcomes [@dienes2014using; @dienes2016bayes; @dienes2018four]:

1. Reject the null / alternative hypothesis
2. Inconclusive (get more data!)
3. Accept the null / alternative hypothesis


</div>


<div style="float: right;width: 35%;">

```{r echo = F, fig.height=2.5}
include_graphics("../gfx/bfs.png")
```
</div>




## Bayes Factor 


<div style="float: left; width: 25%;">

$$
\text{BF} = \frac{p(H_1 \mid y)}{p(H_0 \mid y)} 
$$
</div>


<div style="float: right;width: 65%;">

- How much more probable is one model (hypothesis) over the other?
- How convinced should we be about the evidence for our hypothesis $H_1$ as opposed to, say, a null hypothesis $H_0$?
- Savage-Dickey density ratio for nested models [@jeffreys1961theory; @dickey1970weighted]:
- Height of the posterior density at zero compared to the height of the prior density at zero.

</div>





## Bayes Factor: Savage-Dickey density ratio

<div style="float: left;width: 45%;">

- Posterior: $\mathcal{N}(-32.2, 17.4)$
- Prior: $\mathcal{N}(0, 100)$


```{r}
dnorm(0, 0, 100)
```

```{r}
dnorm(0, mean(beta), sd(beta))
```

```{r}
dnorm(0, 0, 100) / dnorm(0, mean(beta), sd(beta))
```



</div>

<div style="float: right;width: 50%;">


```{r fig.width=5, echo = F}
pd <- tibble(x = seq(-200, 200, by = 10),
             Prior = dnorm(x, 0, 100),
             Posterior = dnorm(x, mean(beta), sd(beta))) %>%
  pivot_longer(Prior:Posterior)

data_at_zero <- filter(pd, x == 0)
pr <- filter(data_at_zero, name == "Prior") %>% pull(value)
po <- filter(data_at_zero, name == "Posterior") %>% pull(value)

ggplot(pd, aes(x = x, y = value, colour = name)) +
  geom_line() +
#  geom_point(data = data_at_zero, aes(x = x, y = value), 
#             colour = "black", size = 2) +
#  geom_label(data = data_at_zero, aes(x = x, y = value, colour = name, label = round(value, 3)), 
#             colour = "black", size = 3, position = position_dodge(.0001)) +
  scale_color_colorblind("") +
  geom_vline(xintercept = 0, linetype = "dotted") +
  labs(y = "density", x = bquote(hat(beta))) #, subtitle = bquote("BF"==.(round(pr/po,2)))) +
```
</div>


## Bayes Factor: Savage-Dickey density ratio

<div style="float: left;width: 45%;">

- Posterior: $\mathcal{N}(-32.2, 17.4)$
- Prior: $\mathcal{N}(0, 25)$


```{r}
dnorm(0, 0, 25)
```

```{r}
dnorm(0, mean(beta), sd(beta))
```

```{r}
dnorm(0, 0, 25) / dnorm(0, mean(beta), sd(beta))
```



</div>

<div style="float: right;width: 50%;">


```{r fig.width=5, echo = F}
pd <- tibble(x = seq(-200, 200, by = 10),
             Prior = dnorm(x, 0, 25),
             Posterior = dnorm(x, mean(beta), sd(beta))) %>%
  pivot_longer(Prior:Posterior)

data_at_zero <- filter(pd, x == 0)
pr <- filter(data_at_zero, name == "Prior") %>% pull(value)
po <- filter(data_at_zero, name == "Posterior") %>% pull(value)

ggplot(pd, aes(x = x, y = value, colour = name)) +
  geom_line() +
#  geom_point(data = data_at_zero, aes(x = x, y = value), 
#             colour = "black", size = 2) +
#  geom_label(data = data_at_zero, aes(x = x, y = value, colour = name, label = round(value, 3)), 
#             colour = "black", size = 3, position = position_dodge(.0001)) +
  scale_color_colorblind("") +
  geom_vline(xintercept = 0, linetype = "dotted") +
  labs(y = "density", x = bquote(hat(beta))) #, subtitle = bquote("BF"==.(round(pr/po,2)))) +
```
</div>



## Bayes Factor: Savage-Dickey density ratio

<div style="float: left;width: 45%;">

- Posterior: $\mathcal{N}(-32.2, 17.4)$
- Prior: $\mathcal{N}(0, 2000)$


```{r}
dnorm(0, 0, 2000)
```

```{r}
dnorm(0, mean(beta), sd(beta))
```

```{r}
dnorm(0, 0, 2000) / dnorm(0, mean(beta), sd(beta))
```



</div>

<div style="float: right;width: 50%;">


```{r fig.width=5, echo = F}
pd <- tibble(x = seq(-200, 200, by = 10),
             Prior = dnorm(x, 0, 2000),
             Posterior = dnorm(x, mean(beta), sd(beta))) %>%
  pivot_longer(Prior:Posterior)

data_at_zero <- filter(pd, x == 0)
pr <- filter(data_at_zero, name == "Prior") %>% pull(value)
po <- filter(data_at_zero, name == "Posterior") %>% pull(value)

ggplot(pd, aes(x = x, y = value, colour = name)) +
  geom_line() +
#  geom_point(data = data_at_zero, aes(x = x, y = value), 
#             colour = "black", size = 2) +
#  geom_label(data = data_at_zero, aes(x = x, y = value, colour = name, label = round(value, 3)), 
#             colour = "black", size = 3, position = position_dodge(.0001)) +
  scale_color_colorblind("") +
  geom_vline(xintercept = 0, linetype = "dotted") +
  labs(y = "density", x = bquote(hat(beta))) #, subtitle = bquote("BF"==.(round(pr/po,2)))) +
```
</div>



## Bayes Factor: Savage-Dickey density ratio


- Regularising (skeptical) priors prevent the model to get overexcited by the sample [his words: @mcelreath2020statistical].
- If in doubt use weakly informative priors like student-t distributions that allow for larger tails, e.g. `student_t(3, 0, 100)`


## Student *t*-distribution: `student_t(df, mean, sd)`

<div style="float: left;width: 35%;">

- Symmetric continuous distribution with fat tails assigning more probability to extreme values.
- $\nu$ parameter controls the degrees of freedom 
- $\nu = 1$ is a Cauchy distribution 
- When $\nu \rightarrow \infty$ the *t*-distribution becomes Gaussian.

</div>


<div style="float: right;width: 60%;">

```{r fig.width=6, echo = F}
library(LaplacesDemon)

x <- seq(-10, 10, by = 0.1)

tibble("t0" = dnorm(x, mean=0, sd=1),
       "t1" = dst(x, mu=0, sigma=1, nu = 1),
       "t2" = dst(x, mu=0, sigma=1, nu = 5),
       "t3" = dst(x, mu=0, sigma=2, nu = 5),
       x = x) %>%
  pivot_longer(-x) %>%
  ggplot(aes(x = x, y = value, colour = name)) +
  geom_line() +
  scale_x_continuous(limits = c(-7, 7)) +
  scale_color_colorblind("Parameter values",
                         breaks = paste0("t",0:3), 
                         labels = c(bquote(mu==0*","~sigma==1),
                                    bquote(mu==0*","~sigma==1*","~nu==1),
                                    bquote(mu==0*","~sigma==1*","~nu==5),
                                    bquote(mu==0*","~sigma==2*","~nu==5))) +
  labs(x = "x", y = "density") +
  theme(legend.justification = "top") 

```
</div>



## Exercise

- Explore `hypothesis()` in the exercise: `hypothesis_testing_bf_1.R`
- Bonus: explore the Savage-Dickey method in `hypothesis_testing_bf_2.R`



## Bayes Factor with `hypothesis()`

H: there is no difference between conjoined and simple NPs

```{r echo = T}
hypothesis(fit_brm, "nptypesimple = 0")
```


H: simple NPs are faster than conjoined NPs

```{r echo = T}
hypothesis(fit_brm, "nptypesimple < 0")
```

H: simple NPs are more than 10 msecs faster than conjoined NPs

```{r echo = T}
hypothesis(fit_brm, "nptypesimple < -10")
```




# Families of distributions



## Families of distributions 

\

"Models are devices that connect theories to data. A model is an instantiation of a theory [...]" [@rouder2016interplay] 

\


- Our models describe how we understand reality.
- Model allows us to describe reality qualitatively (with their parameters) and quantitatively (parameter value estimates).
- Interpretation of parameters depends on data-modeling context.
- At minimum, distribution families (probability models) depend on data type.


## Families of distributions (some important ones)

- **Gaussian**: data come from normal distribution 

```{r eval=F, echo=T}
fit <- brm(outcome ~ predictor + (1|participant), data = data, family = gaussian())
```


## Families of distributions (some important ones)

- **Gaussian**: data come from normal distribution 
- **Bernoulli**: binomial outcomes (yes / no; correct / incorrect) 

```{r eval=F, echo=T}
fit <- brm(outcome ~ predictor + (1|participant), data = data, family = bernoulli())
```

## Families of distributions (some important ones)

- **Gaussian**: data come from normal distribution 
- **Bernoulli**: binomial outcomes (yes / no; correct / incorrect) 
- **Poisson**: count data (number of words / mistakes) [@winter2021poisson]


```{r eval=F, echo=T}
fit <- brm(outcome ~ predictor + (1|participant), data = data, family = poisson())
```

## Families of distributions (some important ones)

- **Gaussian**: data come from normal distribution 
- **Bernoulli**: binomial outcomes (yes / no; correct / incorrect)
- **Poisson**: count data (number of words / mistakes) [@winter2021poisson]
- **Zero-inflated Poisson**: count data with lots of zeros (number of typos per word)


```{r eval=F, echo=T}
fit <- brm(outcome ~ predictor + (1|participant), data = data, family = zero_inflated_poisson())
```


## Families of distributions (some important ones)

- **Gaussian**: data come from normal distribution 
- **Bernoulli**: binomial outcomes (yes / no; correct / incorrect)
- **Poisson**: count data (number of words / mistakes) [@winter2021poisson]
- **Zero-inflated Poisson**: count data with lots of zeros (number of typos per word)
- **Cumulative**: ordinal (ordered categorical) data [@burkner2019ordinal] (Likert scales)


```{r eval=F, echo=T}
fit <- brm(outcome ~ predictor + (1|participant), data = data, family = cumulative()) # or acat, sratio
```


## Families of distributions (some important ones)

- **Gaussian**: data come from normal distribution 
- **Bernoulli**: binomial outcomes (yes / no; correct / incorrect)
- **Poisson**: count data (number of words / mistakes) [@winter2021poisson]
- **Zero-inflated Poisson**: count data with lots of zeros (number of typos per word)
- **Cumulative**: ordinal (ordered categorical) data [@burkner2019ordinal] (Likert scales)
- **Lognormal**: zero bound data with positive skew; also skewed / shifted (log)normal, Wiener Diffusion models etc. [for RT data; @matzke2009psychological]


```{r eval=F, echo=T}
fit <- brm(outcome ~ predictor + (1|participant), data = data, family = lognormal())
```




# Compare probability models of rt data | see e.g. @matzke2009psychological; @roeser2024no

## Probability models of rt data

So far we used a Gaussian model which showed a poor fit to the data.

```{r echo = F}
pp_check(fit_brm, nsamples = 100)
```

Alternative models: skewed normal, shifted (log)normal, Wiener Diffusion models, ex-Gaussian, mixture of lognormal etc. [see @matzke2009psychological; @roeser2024no].




## Gaussian

$$y \sim \mathcal{N}(\mu, \sigma^2)$$

- Data generating process can be described as a normal distribution with mean $\mu$ and standard deviation $\sigma$.



## Lognormal



```{r echo=F}
p_rt <- ggplot(data, aes(x = rt)) +
  geom_density() +
  labs(x = "rt") +
  scale_x_continuous(limits = c(100, 10000), breaks = c(0, 2500, 5000, 7500, 10000))

p_log_rt <- ggplot(data, aes(x = rt)) +
  geom_density() +
  scale_x_log10(limits = c(100, 10000), breaks = c(0, 100, 300, 1000, 3000, 10000)) +
  labs(y = "", x = "log(rt)")

p_rt + p_log_rt 
```


## Lognormal


$$
\log(y) \sim \mathcal{N}(\mu, \sigma^2)
$$

- Often used to address positive skew; e.g. response times [@baa08book]
- Log-values are only defined if $y \in [0, \infty]$
- De-emphasize large values over small values.
- Models the percentage change and not absolute differences:
  - Rather than saying "keystroke intervals are 40 msecs slower", you say "keystrokes are 7% slower". 
  - Difference of 40 msecs can be huge for fast typing but negligible for pauses around 10 secs. 


## Shifted lognormal

$$
\log(y - \exp(\text{ndt})) \sim \mathcal{N}(\mu, \sigma^2)
$$


- Variation of the lognormal distribution: a zero shift would be equivalent to lognormal
- Includes a horizontal shift.
- Useful for modeling rt data because they are typically not just
  - right-skewed
  - non-negative 
- But also
  - positively shifted: there is a minimum time required for any response

Accounts for a minimum rt: The shift parameter represents the minimum possible rt, accounting for the fact that no response can be instantaneous.

## Shifted lognormal (simulated data)

```{r echo=F}
# Set seed for reproducibility
set.seed(123)

# Parameters
n <- 1000
mu <- 6.5                # Mean of the log-transformed values
sigma <- .6            # Std deviation of the log-transformed values
shift <- 500             # Shift parameter (non-decision time)

# Generate Shifted Lognormal Data
rt <- shift + rlnorm(n, meanlog = mu, sdlog = sigma)

# Create a data frame
data <- data.frame(rt = rt)

# Calculate key points
mu_rt <- exp(mu) + shift  # Mean RT in original space
sigma_rt <- (exp(sigma^2) - 1) * exp(2 * mu + sigma^2)  # Variance in original space
mean_shift <- mean(rt)

# Plot the distribution with parameters
ggplot(data, aes(x = rt)) +
  geom_density(alpha = 0.3) +
  geom_vline(xintercept = shift, color = "#e31a1c", linetype = "dashed", size = .5, label = "shift (ndt)") +
  geom_vline(xintercept = mu_rt, color = "#33a02c", linetype = "dashed", size = .5, label = "mean in log space") +
  geom_vline(xintercept = mean(rt), color = "#ff7f00", linetype = "dashed", size = .5, label = "mean rt") +
  annotate("text", x = shift - 100, y = 0.8 * max(density(rt)$y), 
           label = "shift (ndt)", color = "#e31a1c", size = 4, angle = 90) +
  annotate("text", x = mu_rt - 100, y = 0.6 * max(density(rt)$y), 
           label = "mean in log space", color = "#33a02c", size = 4, angle = 90) +
  annotate("text", x = mean_shift + 100, y = 0.2 * max(density(rt)$y), 
           label = "mean rt", color = "#ff7f00", size = 4, angle = 90) +
  
  # Axis labels and theme
  labs(x = "rt") +
  scale_x_continuous(limits = c(0, 5000)) +
  theme(axis.text.y = element_blank(),
        axis.title.y = element_blank(),
        axis.ticks.y = element_blank())

```



## Exercise

Fit two other probability models, namely a lognormal and a shifted lognormal model:

- Complete script `mixed_effects_models_brms_lognormal.R`
- Complete script `mixed_effects_models_brms_shifted_lognormal.R`





# Model comparisons | chapter 11 in @gelman2020regression; chapter 6 in @mcelreath2020statistical

 

## The Gaussian model showed poor fit to data

```{r echo = F}
pp_check(fit_brm, nsamples = 100)
```





## Model comparisons

- How accurately does the model predict new data.
- $R^2$ et al.: more complex models are generally better ( $R^2$ can't go down).
- **Overfitting:** models with more parameters can make unreasonable predictions.
- Generalisations to data that were used to fit the model are over optimistic [@gelman2020regression].
- We will look at both fit and predictive performance of the model.
  



## Compare probability models of rt data

```{r echo = F, eval = F}
files <- list.files("../models", full.names = T)
files <- files[!str_detect(string = files, pattern = "compar|brm.rds")]
plots <- list()

for(file in files){
  fit <- readRDS(file)
  title <- fit$family$family
  plots[[file]] <- pp_check(fit, ndraws = 100) +
    labs(title = str_c("Distribution: ",
                       str_to_sentence(str_replace(title, "_", " "))))
}

all_plots <- wrap_plots(plots, nrow = 2) +
  plot_layout(guides = "collect") &
  theme(plot.title = element_text(size = 10),
        axis.text.x = element_text(size = 8),
        legend.position = "bottom") &
  scale_x_continuous(limits = c(min(data$rt), max(data$rt)))

file_dest <- "../plots/fit2data.png"
ggsave(file_dest, plot = all_plots, width = 6, height = 4)
```

```{r echo = F, fig.height=4.5}
file_dest <- "../plots/fit2data.png"
include_graphics(file_dest)
```



## Leave-One-Out (LOO) cross validation

- Cross validation: performance of a model on **new** data to remove the overfitting problem.
- Leave-One-Out (LOO) Information Criterion (LOO-IC): 
  - Train model on $N-1$ observations 
  - Predict remaining data point from training model.
  - Repeat process $N$ times to predict every observation from a model of the remaining data.
- Adding up prediction results gives an estimate of **expected log-predictive density** ($elpd$); i.e. approximation of results that would be expected for new data.
- `loo()` uses the probability calculations to approximate LOO-IC (i.e. Pareto smoothed importance sampling) [@vehtari2015pareto; @vehtari2017practical].




## Leave-One-Out (LOO) cross validation

<div style="float: left;width: 50%;">

- Approximation involved in `loo()` uses the log posterior predictive densities: how likely is each data point given the distribution parameter estimates?

</div>


<div style="float: right;width: 50%;">

```{r fig.width=5, echo = F}
log_lik(fit_brm) %>% 
  as_tibble() %>% mutate(sample = 1:n()) %>%
  pivot_longer(-sample, names_to = "obs", values_to = "loglik") %>%
  group_by(obs) %>%
  summarise(M = mean(loglik),
            var = var(loglik)) %>%
  mutate(obs = as.numeric(gsub(pattern = "V", replacement = "", obs))) %>%
  ggplot(aes(x = obs, y = M, ymin = M-var, ymax = M+var)) +
  geom_pointrange(fatten = .5) +
  labs(x = "Observations", y = "log-posterior predictive\ndensity (with variance)")
```

</div>




## Leave-One-Out (LOO) cross validation

<div style="float: left;width: 50%;">

```{r echo = T}
loo(fit_brm)
```


</div>

```{r echo = F}
# product of n factors one for each data point: with theta being all parameters
# for LOO CV we perform exclude each data point one at a time which is equivalent to multiplying posterior by factor 1/p(y_i \mid \theta)
# LOO posterior excluding i is p(\theta \ mid y_{-i}) = p(\theta \mid y) / p(y_i \mid \theta) using the the 
# LOO distribution uses the posterior simulatios for \theta and giving each simulation a weight of 1 / p(y_i \mid \theta)
# Weighted simulations is used to approximate the predictice distribution of y_i (the held-out data point)
# $$p(\theta \mid y) \propto p(\theta) \prod^n_{i=1} p(y_i \mid \theta)$$
```

```{r echo = F}
# pointwise density:
# Average likelihood of every observation in training sample
# this is done for each set of parameters sampled from the psoterior distribution
# Average liklihood for each obsersation
# Sum over all observations.
# resulting in the log-pointwise-predictive-density (lppd)

# effective number of parameters is the variance in log-likelihood for every observation: p_waic
# WAIC: -2*(lppd * p_waic)



```





<div style="float: right;width: 50%;">

```{r fig.width=5, echo = F}
log_lik(fit_brm) %>% 
  as_tibble() %>% mutate(sample = 1:n()) %>%
  pivot_longer(-sample, names_to = "obs", values_to = "loglik") %>%
  group_by(obs) %>%
  summarise(M = mean(loglik),
            var = var(loglik)) %>%
  mutate(obs = as.numeric(gsub(pattern = "V", replacement = "", obs))) %>%
  ggplot(aes(x = obs, y = M, ymin = M-var, ymax = M+var)) +
  geom_pointrange(fatten = .5) +
  labs(x = "Observations", y = "log-posterior predictive\ndensity (with variance)")
```

</div>



## Leave-One-Out (LOO) cross validation

<div style="float: left;width: 50%;">

- `elpd_loo`: sum of means (expected log predictive density)
- `p_loo`: sum of variances
- `looic`: $-2 \cdot ($`elpd_loo`$-$`p_loo`$)$ (for deviance scale)


```{r}
log_lik(fit_brm) %>% as_tibble() %>% 
  mutate(sample = 1:n()) %>%
  pivot_longer(-sample, names_to = "obs", 
               values_to = "loglik") %>%
  summarise(mean_loglik = mean(exp(loglik)),
            var_loglik = var(loglik),
            .by = obs) %>% 
  summarise(elpd_loo = sum(log(mean_loglik)), 
            p_loo = sum(var_loglik),
            looic = -2 * (elpd_loo - p_loo))
```


</div>

<div style="float: right;width: 50%;">

```{r fig.width=5, echo = F}
log_lik(fit_brm) %>% 
  as_tibble() %>% mutate(sample = 1:n()) %>%
  pivot_longer(-sample, names_to = "obs", values_to = "loglik") %>%
  group_by(obs) %>%
  summarise(M = mean(loglik),
            var = var(loglik)) %>%
  mutate(obs = as.numeric(gsub(pattern = "V", replacement = "", obs))) %>%
  ggplot(aes(x = obs, y = M, ymin = M-var, ymax = M+var)) +
  geom_pointrange(fatten = .5) +
  labs(x = "Observations", y = "log-posterior predictive\ndensity (with variance)")
```

</div>


## Leave-One-Out (LOO) cross validation

<div style="float: left;width: 50%;">


```{r echo = F}
#difference between two deviances has a chi-squared distribution; factor of 2 scales it that way; also called the Bayesian deviance


# N of parameters
# number of different conjectures for causes of explanations of the data
# How much iformation do we want the model to provide
# how flexible is themodel in fitting the training samples
# penalty term
# expected distance between in-sample and out-of-sample deviance
```

- `elpd_loo` and `looic` rarely have a direct interpretation (as opposed to `loo_R2()`): important are differences between models.
- `p_loo` is the effective number of parameters: how flexible is the model fit.
- Exercise: complete the script `model_comparison.R`
- This script assumes that you have stored the posterior of these models: Gaussian, lognormal, and shifted lognormal



</div>

<div style="float: right;width: 50%;">

```{r fig.width=5, echo = F}
log_lik(fit_brm) %>% 
  as_tibble() %>% mutate(sample = 1:n()) %>%
  pivot_longer(-sample, names_to = "obs", values_to = "loglik") %>%
  group_by(obs) %>%
  summarise(M = mean(loglik),
            var = var(loglik)) %>%
  mutate(obs = as.numeric(gsub(pattern = "V", replacement = "", obs))) %>%
  ggplot(aes(x = obs, y = M, ymin = M-var, ymax = M+var)) +
  geom_pointrange(fatten = .5) +
  labs(x = "Observations", y = "log-posterior predictive density (with variance)")
```

</div>





## Model comparison

```{r eval = T, echo = F}

mc <- readRDS("../models/model_comparison.rda")
mc$ic_diffs__ %>%
  as.data.frame() %>%
  rownames_to_column("comparison") %>% 
  mutate(across(LOOIC, ~ - . / 2),
         across(SE, ~ . / 2),
         elpd_ratio = abs(LOOIC / SE),
         across(where(is.numeric), round, 1),
         across(comparison, ~str_replace(., "-", "vs"))) %>%
  rename_with(.fn = ~str_replace(., "LOOIC", "elpd_diff")) %>% 
  kable() %>%
  kable_styling("striped", 
                 full_width = F) %>%
  column_spec(1, width = "20em") %>%
  add_footnote("`elpd_diff` is often reported as e.g. $\\\\Delta\\\\widehat{elpd}$.")

```





# The end

## Summary

- `brms` isn't much more complicated than `lme4` and comes with more flexibility.
- Priors require some thinking.
- Bayesian models allow straight forward interpretation of parameter values without an arbitrary threshold for significance.


## Recommended reading

- Bürkner tutorials: @brms2; @burkner2019ordinal; @burkner2019bayesian; @winter2021poisson
- Vasishth tutorials: @sorensen2016bayesian; @nicenboim2016statistical; @vasishth2016statistical
- Excellent book-length intros: @gelman2020regression, @mcelreath2020statistical, @kruschke2014doing, @lambert2018student, @lee2014bayesian
- Convince yourself that Bayesian inference is the right answer: @clayton2021bernoulli



## References {.smaller}

<style>
slides > slide { overflow: scroll; }
slides > slide:not(.nobackground):after {
  content: '';
}
</style>



